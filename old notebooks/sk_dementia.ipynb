{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad7eb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Core libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier  # A popular gradient boosting algorithm\n",
    "\n",
    "# Libraries for evaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5753b09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully. Shape: (195196, 1024)\n",
      "       NACCID  NACCADC PACKET  FORMVER  VISITMO  VISITDAY  VISITYR  NACCVNUM  \\\n",
      "0  NACC002909      186      I      3.0       12        28     2022         1   \n",
      "1  NACC002909      186      F      3.0        1        23     2024         2   \n",
      "2  NACC003487      186      I      3.0       11        15     2023         1   \n",
      "3  NACC004352      186      I      3.0       10         5     2021         1   \n",
      "4  NACC004687      186      I      3.0       11        14     2022         1   \n",
      "\n",
      "   NACCAVST  NACCNVST  ...  NPATGAM1  NPATGAM2  NPATGAM3  NPATGAM4  NPATGAM5  \\\n",
      "0         2         2  ...        -4        -4        -4        -4        -4   \n",
      "1         2         2  ...        -4        -4        -4        -4        -4   \n",
      "2         1         1  ...        -4        -4        -4        -4        -4   \n",
      "3         1         1  ...        -4        -4        -4        -4        -4   \n",
      "4         1         1  ...        -4        -4        -4        -4        -4   \n",
      "\n",
      "   NPATGFRN  NPATGFR1  NPATGFR2  NPATGFR3  NPATGFR4  \n",
      "0        -4        -4        -4        -4        -4  \n",
      "1        -4        -4        -4        -4        -4  \n",
      "2        -4        -4        -4        -4        -4  \n",
      "3        -4        -4        -4        -4        -4  \n",
      "4        -4        -4        -4        -4        -4  \n",
      "\n",
      "[5 rows x 1024 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv('./dataset.csv')\n",
    "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found.\")\n",
    "    print(\"Please update the 'pd.read_csv()' line with your file path.\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89d54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable set to: DEMENTED\n",
      "Found 90 available non-medical features in your file.\n",
      "\n",
      "Note: The following features from the data dictionary were not found in your file and will be skipped:\n",
      "['APREFLAN', 'AYRSPAN', 'AYRENGL', 'APCSPAN', 'APCENGL', 'NACCSPNL', 'NACCENGL']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection \n",
    "# 1. DEFINE YOUR TARGET VARIABLE\n",
    "TARGET_VARIABLE = 'DEMENTED'\n",
    "\n",
    "# 2. DEFINE THE MASTER LIST of all possible non-medical features\n",
    "ALL_POSSIBLE_FEATURES = [\n",
    "    # Form A1: Subject Demographics\n",
    "    'NACCAGE', 'SEX', 'EDUC', 'MARISTAT', 'NACCLIVS', 'RESIDENC', 'HANDED',\n",
    "    'HISPANIC', 'RACE', 'RACESEC', 'RACETER', 'PRIMLANG', 'INDEPEND',\n",
    "\n",
    "    # Form A2: Co-participant Demographics\n",
    "    'INRELTO', 'INLIVWTH', 'INVISITS', 'INCALLS',\n",
    "\n",
    "    # Form A3: Subject Family History\n",
    "    'NACCFAM', 'NACCMOM', 'NACCDAD',\n",
    "\n",
    "    # Form A4: Subject Medications\n",
    "    'ANYMEDS',\n",
    "\n",
    "    # Form A5: Subject Health History\n",
    "    'TOBAC30', 'TOBAC100', 'SMOKYRS', 'PACKSPER', 'QUITSMOK', 'ALCOCCAS',\n",
    "    'ALCFREQ', 'ALCOHOL', 'ABUSOTHR', 'CVHATT', 'CVAFIB', 'CVANGIO',\n",
    "    'CVBYPASS', 'CVPACDEF', 'CVPACE', 'CVCHF', 'CVANGINA', 'CVHVALVE',\n",
    "    'CVOTHR', 'HYPERTEN', 'HYPERCHO', 'CBSTROKE', 'NACCSTYR', 'CBTIA',\n",
    "    'NACCTIYR', 'PD', 'PDYR', 'SEIZURES', 'NACCTBI', 'DIABETES', 'DIABTYPE',\n",
    "    'B12DEF', 'THYROID', 'ARTHRIT', 'APNEA', 'RBD', 'INSOMN', 'OTHSLEEP',\n",
    "    'PTSD', 'BIPOLAR', 'SCHIZ', 'DEP2YRS', 'DEPOTHR', 'ANXIETY', 'OCD',\n",
    "    'INCONTU', 'INCONTF',\n",
    "\n",
    "    # Form B1: Physical\n",
    "    'HEIGHT', 'WEIGHT', 'NACCBMI', 'VISION', 'VISCORR', 'VISWCORR',\n",
    "    'HEARING', 'HEARAID', 'HEARWAID',\n",
    "\n",
    "    # Form B9: Self-Reported Decline\n",
    "    'DECSUB', 'DECIN',\n",
    "\n",
    "    # Form B7: Functional Activities\n",
    "    'BILLS', 'TAXES', 'SHOPPING', 'GAMES', 'STOVE', 'MEALPREP',\n",
    "    'EVENTS', 'PAYATTN', 'REMDATES', 'TRAVEL',\n",
    "\n",
    "    # Milestones Form\n",
    "    'NACCNURP',\n",
    "\n",
    "    # Form CLS: Linguistic History (These are the ones causing the error)\n",
    "    'APREFLAN', 'AYRSPAN', 'AYRENGL', 'APCSPAN', 'APCENGL',\n",
    "    'NACCSPNL', 'NACCENGL'\n",
    "]\n",
    "\n",
    "# 3. CRITICAL STEP: Filter the list to only include features in your CSV\n",
    "NON_MEDICAL_FEATURES = [col for col in ALL_POSSIBLE_FEATURES if col in df.columns]\n",
    "\n",
    "# Find and report any missing features (for your information)\n",
    "missing_from_csv = [col for col in ALL_POSSIBLE_FEATURES if col not in df.columns]\n",
    "\n",
    "print(f\"Target variable set to: {TARGET_VARIABLE}\")\n",
    "print(f\"Found {len(NON_MEDICAL_FEATURES)} available non-medical features in your file.\")\n",
    "\n",
    "if missing_from_csv:\n",
    "    print(\"\\nNote: The following features from the data dictionary were not found in your file and will be skipped:\")\n",
    "    print(missing_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d474f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def engineer_features(X_df):\n",
    "    \"\"\"\n",
    "    Takes the feature DataFrame (X) and adds new engineered features.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid changing the original data\n",
    "    X_engineered = X_df.copy()\n",
    "\n",
    "    # --- 1. Create Composite Scores (Summing related risks) ---\n",
    "\n",
    "    # List of all functional activity columns (Form B7)\n",
    "    functional_cols = [\n",
    "        'BILLS', 'TAXES', 'SHOPPING', 'GAMES', 'STOVE',\n",
    "        'MEALPREP', 'EVENTS', 'PAYATTN', 'REMDATES', 'TRAVEL'\n",
    "    ]\n",
    "    # Fill NaNs with 0 (assume 'no difficulty') before summing\n",
    "    X_engineered['FUNC_DIFFICULTY_SCORE'] = X_engineered[functional_cols].fillna(\n",
    "        0).sum(axis=1)\n",
    "\n",
    "    # List of self-reported cardiovascular conditions (Form A5)\n",
    "    cvd_cols = [\n",
    "        'CVHATT', 'CVAFIB', 'CVANGIO', 'CVBYPASS', 'CVPACDEF', 'CVPACE',\n",
    "        'CVCHF', 'CVANGINA', 'CVHVALVE', 'HYPERTEN', 'HYPERCHO', 'CBSTROKE', 'CBTIA'\n",
    "    ]\n",
    "    # Fill NaNs with 0 (assume 'absent') before summing to get a risk count\n",
    "    X_engineered['CVD_RISK_COUNT'] = X_engineered[cvd_cols].fillna(\n",
    "        0).sum(axis=1)\n",
    "\n",
    "    # List of self-reported psychiatric conditions (Form A5)\n",
    "    psych_cols = [\n",
    "        'PTSD', 'BIPOLAR', 'SCHIZ', 'DEP2YRS', 'DEPOTHR', 'ANXIETY', 'OCD'\n",
    "    ]\n",
    "    X_engineered['PSYCH_RISK_COUNT'] = X_engineered[psych_cols].fillna(\n",
    "        0).sum(axis=1)\n",
    "\n",
    "    # --- 2. Bin Numerical Features (Turning numbers into categories) ---\n",
    "\n",
    "    # Bin BMI into standard categories\n",
    "    bmi_bins = [0, 18.5, 24.9, 29.9, 100]\n",
    "    bmi_labels = ['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    "    X_engineered['BMI_CATEGORY'] = pd.cut(\n",
    "        X_engineered['NACCBMI'], bins=bmi_bins, labels=bmi_labels, right=False)\n",
    "\n",
    "    # Bin Age into groups\n",
    "    age_bins = [0, 65, 75, 85, 120]\n",
    "    age_labels = ['65_or_less', '66-75', '76-85', '86_and_up']\n",
    "    X_engineered['AGE_GROUP'] = pd.cut(\n",
    "        X_engineered['NACCAGE'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "    # --- 3. Create Interaction Features ---\n",
    "\n",
    "    # Check interaction between age and education\n",
    "    # (The pipeline will handle imputing NaNs in the original NACCAGE/EDUC columns)\n",
    "    X_engineered['AGE_X_EDUC'] = X_engineered['NACCAGE'] * X_engineered['EDUC']\n",
    "\n",
    "    print(\"Feature engineering complete.\")\n",
    "    print(\n",
    "        f\"Original features: {len(X_df.columns)}, New features: {len(X_engineered.columns)}\")\n",
    "\n",
    "    return X_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eed6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (as np.nan) identified: 6850211\n",
      "Feature engineering complete.\n",
      "Original features: 90, New features: 96\n",
      "Total numeric features for pipeline: 15\n",
      "Total categorical features for pipeline: 81\n",
      "Preprocessing pipelines updated with new features.\n",
      "\n",
      "Data split into training and testing sets.\n",
      "X_train shape: (156156, 96)\n",
      "X_test shape: (39040, 96)\n",
      "y_train shape: (156156,)\n",
      "y_test shape: (39040,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# 1. --- Select X and y ---\n",
    "df_clean = df.dropna(subset=[TARGET_VARIABLE])\n",
    "\n",
    "# NON_MEDICAL_FEATURES should be available from running Cell 3\n",
    "X = df_clean[NON_MEDICAL_FEATURES]\n",
    "y = df_clean[TARGET_VARIABLE].astype(int)\n",
    "\n",
    "# 2. --- Data Cleaning ---\n",
    "MISSING_CODES = [\n",
    "    -4, 8, 9, 88, 99, 888, 999, 8888, 9999,\n",
    "    95, 96, 97, 98, 995, 996, 997, 998\n",
    "]\n",
    "X = X.replace(MISSING_CODES, np.nan)\n",
    "print(f\"Missing values (as np.nan) identified: {X.isna().sum().sum()}\")\n",
    "\n",
    "# 3. --- Apply Feature Engineering ---\n",
    "# This calls the function from Cell 4\n",
    "X_engineered = engineer_features(X)\n",
    "\n",
    "# 4. --- Define Preprocessing Pipelines (with new features) ---\n",
    "\n",
    "# --- FIX IS HERE ---\n",
    "# This list needs to be defined within this cell\n",
    "ALL_POSSIBLE_NUMERIC_FEATURES = [\n",
    "    'NACCAGE', 'EDUC', 'SMOKYRS', 'PACKSPER', 'QUITSMOK', 'NACCSTYR',\n",
    "    'NACCTIYR', 'PDYR', 'HEIGHT', 'WEIGHT', 'NACCBMI', 'AYRSPAN',\n",
    "    'AYRENGL', 'APCSPAN', 'APCENGL'\n",
    "]\n",
    "# --- END FIX ---\n",
    "\n",
    "# Get the original feature lists\n",
    "NUMERIC_FEATURES_ORIGINAL = [\n",
    "    col for col in NON_MEDICAL_FEATURES if col in ALL_POSSIBLE_NUMERIC_FEATURES]\n",
    "CATEGORICAL_FEATURES_ORIGINAL = [\n",
    "    col for col in NON_MEDICAL_FEATURES if col not in NUMERIC_FEATURES_ORIGINAL]\n",
    "\n",
    "# Add our new features to the lists for preprocessing\n",
    "NUMERIC_FEATURES = NUMERIC_FEATURES_ORIGINAL + [\n",
    "    'FUNC_DIFFICULTY_SCORE', 'CVD_RISK_COUNT', 'PSYCH_RISK_COUNT', 'AGE_X_EDUC'\n",
    "]\n",
    "CATEGORICAL_FEATURES = CATEGORICAL_FEATURES_ORIGINAL + [\n",
    "    'BMI_CATEGORY', 'AGE_GROUP'\n",
    "]\n",
    "\n",
    "# Remove duplicates just in case\n",
    "NUMERIC_FEATURES = list(\n",
    "    set([col for col in NUMERIC_FEATURES if col in X_engineered.columns]))\n",
    "CATEGORICAL_FEATURES = list(\n",
    "    set([col for col in CATEGORICAL_FEATURES if col in X_engineered.columns]))\n",
    "\n",
    "print(f\"Total numeric features for pipeline: {len(NUMERIC_FEATURES)}\")\n",
    "print(f\"Total categorical features for pipeline: {len(CATEGORICAL_FEATURES)}\")\n",
    "\n",
    "# Create the pipelines (same as before)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, NUMERIC_FEATURES),\n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any original columns we didn't use\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipelines updated with new features.\")\n",
    "\n",
    "# 5. --- Split the Data ---\n",
    "# We split the *engineered* data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_engineered, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into training and testing sets.\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150da349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model on ENGINEERED features...\n",
      "\n",
      "--- Random Forest (Engineered) Evaluation ---\n",
      "Accuracy: 0.9327\n",
      "AUC Score: 0.9782\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not at risk (0)       0.95      0.96      0.95     27522\n",
      "    At risk (1)       0.89      0.88      0.88     11518\n",
      "\n",
      "       accuracy                           0.93     39040\n",
      "      macro avg       0.92      0.92      0.92     39040\n",
      "   weighted avg       0.93      0.93      0.93     39040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classfier\n",
    "\n",
    "if not df.empty:\n",
    "    # Create the full model pipeline\n",
    "    rf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
    "    ])\n",
    "\n",
    "    # --- Train the model ---\n",
    "    print(\"Training Random Forest model on ENGINEERED features...\")\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # --- Evaluate the model ---\n",
    "    print(\"\\n--- Random Forest (Engineered) Evaluation ---\")\n",
    "    y_pred_rf = rf_pipeline.predict(X_test)\n",
    "    y_proba_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_proba_rf):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=[\"Not at risk (0)\", \"At risk (1)\"]))\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty. Please load data in Cell 2 or 5.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
